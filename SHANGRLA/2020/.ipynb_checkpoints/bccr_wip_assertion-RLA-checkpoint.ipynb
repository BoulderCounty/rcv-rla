{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assertion RLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the assertion audit tool\n",
    "\n",
    "The tool requires as input:\n",
    "\n",
    "+ audit-specific and contest-specific parameters, such as\n",
    "    - whether to sample with or without replacement\n",
    "    - the name of the risk function to use, and any parameters it requires\n",
    "    - a risk limit for each contest to be audited\n",
    "    - the social choice function for each contest, including the number of winners\n",
    "    - candidate identifiers\n",
    "+ a ballot manifest**\n",
    "+ a random seed\n",
    "+ a file of cast vote records\n",
    "+ reported results for each contest\n",
    "+ json files of assertions for IRV contests (one file per IRV contest)\n",
    "+ human reading of voter intent from the paper cards selected for audit\n",
    "\n",
    "** The ballot manifest could be only for cards purported to contain the\n",
    "contests under audit (manifest_type == \"STYLE\"), or could include cards that might not contain the\n",
    "contest (manifest_type == \"ALL\"). These are treated differently. If the sample is to be drawn only from cards that--according to the CVR--contain the contest, and a sampled card turns out not to\n",
    "contain the contest, that is considered a discrepancy, dealt with using the \"phantoms to zombies\" approach.\n",
    "It is assumed that every CVR corresponds to a card in the manifest, but there might\n",
    "be cards cast in the contest for which there is no corresponding CVR. In that case,\n",
    "phantom records are created to ensure that the audit is still truly risk-limiting.\n",
    "\n",
    "Given an independent (i.e., not relying on the voting system) upper bound on the number of cards that contain the contest, if the number of CVRs that contain the contest does not exceed that bound, we can sample from paper purported to contain the contest and use the \"zombies\" approach (Banuelos & Stark) to deal with missing CVRs. This can greatly increase the efficiency of the audit if the contest is on only a small percentage of the cast cards.\n",
    "\n",
    "Any sampled phantom card (i.e., a card for which there are no CVRs) is treated as if its CVR is a non-vote (which it is), and as if its MVR was least favorable (a \"zombie\" producing the greatest doubt in every assertion, separately). Any sampled card for which\n",
    "there is a CVR is compared to its corresponding CVR. \n",
    "If the card turns out not to contain the contest (despite the fact that the CVR says it does), the MVR is treated in the least favorable way for each assertion (i.e., as a zombie rather than as a non-vote).\n",
    "\n",
    "The tool helps select cards for audit, and reports when the audit has found sufficiently strong evidence to stop.\n",
    "\n",
    "The tool exports a log of all the audit inputs except the CVR file, but including the auditors' manually determined voter intent from the audited cards.\n",
    "\n",
    "The current version uses a single sample to audit all contests. It is possible to refine things to target smaller contests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import math\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import copy\n",
    "\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from cryptorandom.cryptorandom import SHA256\n",
    "from cryptorandom.sample import sample_by_index\n",
    "\n",
    "from assertion_audit_utils import \\\n",
    "    Assertion, Assorter, CVR, TestNonnegMean, check_audit_parameters, find_margins,\\\n",
    "    find_p_values, find_sample_size, new_sample_size, prep_sample, summarize_status,\\\n",
    "    write_audit_parameters\n",
    "from dominion_tools import \\\n",
    "    prep_dominion_manifest, sample_from_cvr, write_cards_sampled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audit parameters.\n",
    "\n",
    "* `seed`: the numeric seed for the pseudo-random number generator used to draw sample \n",
    "* `replacement`: whether to sample with replacement. If the sample is drawn with replacement, gamma must also be specified.\n",
    "* `risk_function`: the function to be used to measure risk. Options are `kaplan_markov`,`kaplan_wald`,`kaplan_kolmogorov`,`wald_sprt`,`kaplan_martingale`. Not all risk functions work with every social choice function. `wald_sprt` applies only to plurality contests.\n",
    "* `g`: a parameter to hedge against the possibility of observing a maximum overstatement. Require $g \\in [0, 1)$ for `kaplan_kolmogorov`, `kaplan_markov`, and `kaplan_wald`.\n",
    "* `N_cards`: an upper bound on the number of pieces of paper cast in the contest. This should be derived independently of the voting system. A ballot consists of one or more cards.\n",
    "\n",
    "----\n",
    "\n",
    "* `cvr_file`: filename for CVRs (input)\n",
    "* `manifest_file`: filename for ballot manifest (input)\n",
    "* `manifest_type`: \"STYLE\" if the manifest is supposed to list only cards that contain the contests under audit; \"ALL\" if the manifest contains all cards cast in the election\n",
    "* `assertion_file`: filename of assertions for IRV contests, in RAIRE format\n",
    "* `sample_file`: filename for sampled card identifiers (output)\n",
    "* `mvr_file`: filename for manually ascertained votes from sampled cards (input)\n",
    "* `log_file`: filename for audit log (output)\n",
    "\n",
    "----\n",
    "\n",
    "* `error_rate`: expected rate of 1-vote overstatements. Recommended value $\\ge$ 0.001 if there are hand-marked ballots. Larger values increase the initial sample size, but make it more likely that the audit will conclude in a single round if the audit finds errors\n",
    "\n",
    "* `contests`: a dict of contest-specific data \n",
    "    + the keys are unique contest identifiers for contests under audit\n",
    "    + the values are dicts with keys:\n",
    "        - `risk_limit`: the risk limit for the audit of this contest\n",
    "        - `cards_cast`: an upper bound on the number of cast cards that contain the contest\n",
    "        - `choice_function`: `plurality`, `supermajority`, or `IRV`\n",
    "        - `n_winners`: number of winners for majority contests. (Multi-winner IRV not supported; multi-winner super-majority is nonsense)\n",
    "        - `share_to_win`: for super-majority contests, the fraction of valid votes required to win, e.g., 2/3.\n",
    "        - `candidates`: list of names or identifiers of candidates\n",
    "        - `reported_winners` : list of identifier(s) of candidate(s) reported to have won. Length should equal `n_winners`.\n",
    "        - `assertion_file`: filename for a set of json descriptors of Assertions (see technical documentation) that collectively imply the reported outcome of the contest is correct. Required for IRV; ignored for other social choice functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 93686630803205229070  # use, e.g., 20 rolls of a 10-sided die. Seed doesn't have to be numeric\n",
    "replacement = False\n",
    "risk_function = \"kaplan_martingale\"\n",
    "risk_fn = lambda x: TestNonnegMean.kaplan_martingale(x, N_cards)[0]\n",
    "g=0.1\n",
    "N_cards = 2374\n",
    "#146662 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvr_file = '/rcv-data/bccr/RAIRE.txt'\n",
    "manifest_file = '/rcv-data/bccr/manifest.xlsx'\n",
    "manifest_type = 'STYLE'\n",
    "sample_file = '/rcv-data/bccr/sample.csv'\n",
    "mvr_file = '/rcv-data/mvr.json'\n",
    "log_file = '/rcv-data/log.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = 0.002      # expect 2 1-vote overstatements per 1000 ballots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # contests to audit. Edit with details of your contest (eg., Contest 339 is the DA race)\n",
    "# contests = {'339':{'risk_limit':0.05,\n",
    "#                      'choice_function':'IRV',\n",
    "#                      'n_winners':1,\n",
    "#                      'candidates':['15','16','17','18'],\n",
    "#                      'reported_winners' : ['15'],\n",
    "#                      'assertion_file' : '/rcv-data/bccr/test_assertions.json'\n",
    "#                     }\n",
    "#            }\n",
    "contests = {'1':{'risk_limit':0.05,\n",
    "                     'choice_function':'IRV',\n",
    "                     'n_winners':1,\n",
    "                     'candidates':['1','2','3'],\n",
    "                     'reported_winners' : ['1'],\n",
    "                     'assertion_file' : '/rcv-data/bccr/bc-assertions.json'\n",
    "                    }\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of other social choice functions:\n",
    "\n",
    "> contests =  {'city_council':{'risk_limit':0.05,\n",
    "                     'choice_function':'plurality',\n",
    "                     'n_winners':3,\n",
    "                     'candidates':['Doug','Emily','Frank','Gail','Harry'],\n",
    "                     'reported_winners' : ['Doug', 'Emily', 'Frank']\n",
    "                    },\n",
    "            'measure_1':{'risk_limit':0.05,\n",
    "                     'choice_function':'supermajority',\n",
    "                     'share_to_win':2/3,\n",
    "                     'n_winners':1,\n",
    "                     'candidates':['yes','no'],\n",
    "                     'reported_winners' : ['yes']\n",
    "                    }                  \n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the assertions for the IRV contest\n",
    "for c in contests:\n",
    "    if contests[c]['choice_function'] == 'IRV':\n",
    "        with open(contests[c]['assertion_file'], 'r') as f:\n",
    "            contests[c]['assertion_json'] = json.load(f)['audits'][0]['assertions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the dict of dicts of assertions for each contest\n",
    "all_assertions = Assertion.make_all_assertions(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'1 v 3 elim ': <assertion_audit_utils.Assertion at 0xffff80630e90>,\n",
       "  '1 v 3 elim 2': <assertion_audit_utils.Assertion at 0xffff7f6f2ed0>,\n",
       "  '1 v 2 elim 3': <assertion_audit_utils.Assertion at 0xffff7f6f2fd0>}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_assertions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the ballot manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special for Primary/Dominion manifest format\n",
    "manifest = pd.read_excel(manifest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the CVRs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1022 rows\n"
     ]
    }
   ],
   "source": [
    "cvr_input = []\n",
    "with open(cvr_file) as f:\n",
    "    cvr_reader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "    for row in cvr_reader:\n",
    "        cvr_input.append(row)\n",
    "\n",
    "print(\"Read {} rows\".format(len(cvr_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging, there are CVRs for 1020 cards\n"
     ]
    }
   ],
   "source": [
    "# Import CVRs\n",
    "cvr_list = CVR.from_raire(cvr_input)\n",
    "print(\"After merging, there are CVRs for {} cards\".format(len(cvr_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn RAIRE-style identifiers into SF-style by substituting \"-\" for \"_\"\n",
    "for c in cvr_list:\n",
    "    c.set_id(str(c.id).replace(\"_\",\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 105-1-42 votes: {'1': {'2': 1, '1': 2, '3': 3}} phantom: False\n",
      "id: 105-1-41 votes: {'1': {'2': 1, '1': 2, '3': 3}} phantom: False\n",
      "id: 105-1-23 votes: {'1': {'1': 1, '2': 2, '3': 3}} phantom: False\n",
      "id: 105-1-19 votes: {'1': {'1': 1, '2': 2, '3': 3}} phantom: False\n",
      "id: 105-1-1 votes: {'1': {'1': 1, '2': 2, '3': 3}} phantom: False\n",
      "id: 105-1-44 votes: {'1': {'3': 1, '2': 2, '1': 3}} phantom: False\n",
      "id: 105-1-43 votes: {'1': {'2': 1, '1': 2, '3': 3}} phantom: False\n",
      "id: 105-1-26 votes: {'1': {'1': 1, '2': 2, '3': 3}} phantom: False\n",
      "id: 105-1-20 votes: {'1': {'1': 1, '2': 2, '3': 3}} phantom: False\n",
      "id: 105-1-13 votes: {'1': {'2': 1, '1': 2, '3': 3}} phantom: False\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(str(cvr_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/SHANGRLA-bccr-old/Code/dominion_tools.py:40: UserWarning: The CVR list does not account for every card cast in the contest; adding a phantom batch to the manifest\n",
      "  warnings.warn('The CVR list does not account for every card cast in the contest; adding a phantom batch to the manifest')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tray #</th>\n",
       "      <th>Tabulator Number</th>\n",
       "      <th>Batch Number</th>\n",
       "      <th>Total Ballots</th>\n",
       "      <th>VBMCart.Cart number</th>\n",
       "      <th>cum_cards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>3</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>149</td>\n",
       "      <td>3</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>1195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>1355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>1503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>1669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>6</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>1807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>7</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>2102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>9</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>10</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>2354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>None</td>\n",
       "      <td>phantom</td>\n",
       "      <td>1</td>\n",
       "      <td>1354</td>\n",
       "      <td>None</td>\n",
       "      <td>3728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tray # Tabulator Number Batch Number  Total Ballots VBMCart.Cart number  \\\n",
       "0       1              103            1            150                   3   \n",
       "1       1              103            2            146                   3   \n",
       "2       1              103            3            150                   3   \n",
       "3       1              103            4            149                   3   \n",
       "4       1              105            1            150                   2   \n",
       "5       1              105            2            150                   2   \n",
       "6       1              105            3            150                   2   \n",
       "7       1              105            4            150                   2   \n",
       "8       1              105            5             12                   3   \n",
       "9       1              108            2            148                   1   \n",
       "10      1              108            3            148                   1   \n",
       "11      1              108            4             22                   1   \n",
       "12      1              108            5            144                   1   \n",
       "13      1              108            6            138                   1   \n",
       "14      1              108            7            145                   1   \n",
       "15      1              108            8            150                   1   \n",
       "16      1              108            9            150                   1   \n",
       "17      1              108           10            102                   1   \n",
       "18      1              108           11             20                   1   \n",
       "19   None          phantom            1           1354                None   \n",
       "\n",
       "    cum_cards  \n",
       "0         150  \n",
       "1         296  \n",
       "2         446  \n",
       "3         595  \n",
       "4         745  \n",
       "5         895  \n",
       "6        1045  \n",
       "7        1195  \n",
       "8        1207  \n",
       "9        1355  \n",
       "10       1503  \n",
       "11       1525  \n",
       "12       1669  \n",
       "13       1807  \n",
       "14       1952  \n",
       "15       2102  \n",
       "16       2252  \n",
       "17       2354  \n",
       "18       2374  \n",
       "19       3728  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that there is a CVR for every card cast in the contest. If not, add phantoms.\n",
    "\n",
    "n_cvrs = len(cvr_list)\n",
    "manifest, manifest_cards, phantom_cards = prep_dominion_manifest(manifest, N_cards, n_cvrs)\n",
    "\n",
    "manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1354 phantom records\n"
     ]
    }
   ],
   "source": [
    "# Create CVRs and MVRs for phantom cards\n",
    "# If the sample draws a phantom card, these CVRs will be used in the comparison.\n",
    "# phantom MVRs should be treated as zeros by the Assorter for every contest\n",
    "phantom_vrs = []\n",
    "for i in range(phantom_cards):\n",
    "    phantom_vrs.append(CVR(id='phantom-1-'+str(i+1), votes={}, phantom = True))  # matches expected RAIRE id for parsing later\n",
    "    \n",
    "cvr_list = cvr_list + phantom_vrs\n",
    "\n",
    "print(\"Created {} phantom records\".format(len(phantom_vrs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2374"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifest_cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum assorter margin 0.03706823925863523\n",
      "margins in contest 1\n",
      "1 v 3 elim  0.038331929233361484\n",
      "1 v 3 elim 2 0.03706823925863523\n",
      "1 v 2 elim 3 0.03875315922493683\n"
     ]
    }
   ],
   "source": [
    "# find the mean of the assorters for the CVRs and check whether the assertions are met\n",
    "min_margin = find_margins(contests, all_assertions, cvr_list)\n",
    "\n",
    "print(\"minimum assorter margin {}\".format(min_margin))\n",
    "for c in contests:\n",
    "    print(\"margins in contest {}\".format(c))\n",
    "    for a, m in contests[c]['margins'].items():\n",
    "        print(a, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_audit_parameters(risk_function, g, error_rate, contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_audit_parameters(log_file, seed, replacement, risk_function, g, N_cards, n_cvrs, \\\n",
    "                       manifest_cards, phantom_cards, error_rate, contests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up for sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find initial sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find initial sample size\n",
    "#ss_fn = lambda m, r: TestNonnegMean.kaplan_martingale_sample_size(N_cards, m,\\\n",
    "#                    error_rate = 0.001, alpha=r)\n",
    "#sample_size = find_sample_size(contests, all_assertions, sample_size_function = ss_fn)\n",
    "#sample_size\n",
    "\n",
    "# Mayoral election for BC test data (to speed up test runs, set at previously computed value)\n",
    "sample_size = 181\n",
    "sample_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample includes 103 phantom cards.\n"
     ]
    }
   ],
   "source": [
    "# draw the initial sample\n",
    "prng = SHA256(seed)\n",
    "sample = sample_by_index(N_cards, sample_size, prng=prng) # 1-indexed\n",
    "n_phantom_sample = np.sum([cvr_list[i].phantom for i in sample])\n",
    "print(\"The sample includes {} phantom cards.\".format(n_phantom_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvr_sample_lookup, cvr_sample, mvr_phantoms_sample = sample_from_cvr(cvr_list, manifest, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the sample\n",
    "write_cards_sampled(sample_file, cvr_sample_lookup, print_phantoms=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the audited sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mvr_file) as f:\n",
    "    mvr_json = json.load(f)\n",
    "\n",
    "mvr_sample = CVR.from_dict(mvr_json['ballots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add MVRs for phantoms\n",
    "mvr_sample = mvr_sample + mvr_phantoms_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find measured risks for all assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_sample(mvr_sample, cvr_sample)\n",
    "p_max = find_p_values(contests, all_assertions, mvr_sample, cvr_sample, manifest_type, \\\n",
    "                      risk_function= risk_fn)\n",
    "print(\"maximum assertion p-value {}\".format(p_max))\n",
    "done = summarize_status(contests, all_assertions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the status of the audit \n",
    "write_audit_parameters(log_file, seed, replacement, risk_function, g, N_cards, n_cvrs, \\\n",
    "                       manifest_cards, phantom_cards, error_rate, contests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many more cards should be audited?\n",
    "\n",
    "Estimate how many more cards will need to be audited to confirm any remaining contests. The enlarged sample size is based on:\n",
    "\n",
    "* cards already sampled\n",
    "* the assumption that we will continue to see errors at the same rate observed in the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_size = new_sample_size(contests, all_assertions, mvr_sample, cvr_sample, manifest_type,\\\n",
    "            risk_function= lambda x: TestNonnegMean.kaplan_martingale(x, N_cards)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment the sample\n",
    "# reset the seed\n",
    "prng = SHA256(seed)\n",
    "old_sample = sample\n",
    "sample = sample_by_index(N_cards, new_size, prng=prng)\n",
    "incremental_sample = np.sort(list(set(sample) - set(old_sample)))\n",
    "n_phantom_sample = np.sum([cvr_list[i].phantom for i in incremental_sample])\n",
    "print(\"The incremental sample includes {} phantom cards.\".format(n_phantom_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvr_sample_lookup_new, cvr_sample_new, mvr_phantoms_sample_new = \\\n",
    "                sample_from_cvr(cvr_list, manifest, incremental_sample)\n",
    "write_cards_sampled(sample_file, cvr_sample_lookup_new, print_phantoms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mvr_json should contain the complete set of mvrs, including those in previous rounds\n",
    "\n",
    "with open(mvr_file) as f:\n",
    "    mvr_json = json.load(f)\n",
    "\n",
    "mvr_sample = CVR.from_dict(mvr_json['ballots']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile entire sample\n",
    "cvr_sample_lookup, cvr_sample, mvr_phantoms_sample = sample_from_cvr(cvr_list, manifest, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add MVRs for phantoms\n",
    "mvr_sample = mvr_sample + mvr_phantoms_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find measured risks for all assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_sample(mvr_sample, cvr_sample)\n",
    "p_max = find_p_values(contests, all_assertions, mvr_sample, cvr_sample, manifest_type, \\\n",
    "                      risk_function= risk_fn)\n",
    "print(\"maximum assertion p-value {}\".format(p_max))\n",
    "done = summarize_status(contests, all_assertions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the status of the audit \n",
    "write_audit_parameters(log_file, seed, replacement, risk_function, g, N_cards, n_cvrs, \\\n",
    "                       manifest_cards, phantom_cards, error_rate, contests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "widgets": {
   "state": {
    "6cab9cab294247839758fa9e8d64d122": {
     "views": [
      {
       "cell_index": 42
      }
     ]
    },
    "b7b0321f834d45ebb1bdc036fba7a916": {
     "views": [
      {
       "cell_index": 38
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
